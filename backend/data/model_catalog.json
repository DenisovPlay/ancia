{
  "version": 1,
  "models": [
    {
      "id": "qwen2.5-0.5b-instruct-mlx-4bit",
      "label": "Qwen2.5 0.5B Instruct",
      "repo": "lmstudio-community/Qwen2.5-0.5B-Instruct-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen2.5-0.5B-Instruct-MLX-4bit",
      "family": "Qwen2.5",
      "size": "0.5B",
      "quantization": "MLX 4bit",
      "description": "Быстрая lightweight-модель для простых чатов и tool-calling.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "compact",
      "max_context": 3072,
      "estimated_unified_memory_bytes": 2000000000
    },
    {
      "id": "qwen2.5-1.5b-instruct-mlx-4bit",
      "label": "Qwen2.5 1.5B Instruct",
      "repo": "lmstudio-community/Qwen2.5-1.5B-Instruct-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen2.5-1.5B-Instruct-MLX-4bit",
      "family": "Qwen2.5",
      "size": "1.5B",
      "quantization": "MLX 4bit",
      "description": "Сбалансированная модель с лучшим качеством reasoning и инструментов.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "compact",
      "max_context": 4096,
      "estimated_unified_memory_bytes": 3200000000
    },
    {
      "id": "qwen2.5-3b-instruct-mlx-4bit",
      "label": "Qwen2.5 3B Instruct",
      "repo": "lmstudio-community/Qwen2.5-3B-Instruct-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen2.5-3B-Instruct-MLX-4bit",
      "family": "Qwen2.5",
      "size": "3B",
      "quantization": "MLX 4bit",
      "description": "Улучшенное качество ответов и tool-calling для повседневной работы.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "balanced",
      "max_context": 4096,
      "estimated_unified_memory_bytes": 5200000000
    },
    {
      "id": "qwen2.5-7b-instruct-mlx-4bit",
      "label": "Qwen2.5 7B Instruct",
      "repo": "lmstudio-community/Qwen2.5-7B-Instruct-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen2.5-7B-Instruct-MLX-4bit",
      "family": "Qwen2.5",
      "size": "7B",
      "quantization": "MLX 4bit",
      "description": "Более сильная text-модель для сложных задач и агентных сценариев.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 9500000000
    },
    {
      "id": "qwen3-vl-4b-instruct-mlx-4bit",
      "label": "Qwen3-VL 4B Instruct",
      "repo": "lmstudio-community/Qwen3-VL-4B-Instruct-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-VL-4B-Instruct-MLX-4bit",
      "family": "Qwen3-VL",
      "size": "4B",
      "quantization": "MLX 4bit",
      "description": "Vision+Language модель с поддержкой tool-calling.",
      "supports_tools": true,
      "supports_vision": true,
      "supports_documents": true,
      "recommended_tier": "balanced",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 6500000000
    },
    {
      "id": "ministral-3-3b-instruct-mlx-4bit",
      "label": "Ministral 3 3B Instruct",
      "repo": "mlx-community/Ministral-3-3B-Instruct-2512-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Ministral-3-3B-Instruct-2512-4bit",
      "family": "Ministral",
      "size": "3.3B",
      "quantization": "MLX 4bit",
      "description": "Компактная модель Mistral с хорошим tool-calling и умеренным потреблением памяти.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "compact",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 4300000000
    },
    {
      "id": "qwen3-vl-8b-instruct-mlx-4bit",
      "label": "Qwen3-VL 8.0B Instruct",
      "repo": "lmstudio-community/Qwen3-VL-8B-Instruct-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-VL-8B-Instruct-MLX-4bit",
      "family": "Qwen3-VL",
      "size": "8.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-VL-8B-Instruct-MLX-4bit. Vision + Tool-calling. Теги: mlx, safetensors, qwen3_vl, image-text-to-text, conversational, base_model:Qwen/Qwen3-VL-8B-Instruct.",
      "supports_tools": true,
      "supports_vision": true,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 5500000000
    },
    {
      "id": "qwen3-coder-30b-a3b-instruct-mlx-4bit",
      "label": "Qwen3 30.0B Instruct",
      "repo": "lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-4bit",
      "family": "Qwen3",
      "size": "30.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-4bit. Tool-calling. Теги: transformers, safetensors, qwen3_moe, text-generation, mlx, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 19800000000
    },
    {
      "id": "qwen3-vl-30b-a3b-instruct-mlx-4bit",
      "label": "Qwen3-VL 30.0B Instruct",
      "repo": "lmstudio-community/Qwen3-VL-30B-A3B-Instruct-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-VL-30B-A3B-Instruct-MLX-4bit",
      "family": "Qwen3-VL",
      "size": "30.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-VL-30B-A3B-Instruct-MLX-4bit. Vision + Tool-calling. Теги: mlx, safetensors, qwen3_vl_moe, image-text-to-text, conversational, base_model:Qwen/Qwen3-VL-30B-A3B-Instruct.",
      "supports_tools": true,
      "supports_vision": true,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 19800000000
    },
    {
      "id": "qwen2-5-coder-14b-instruct-mlx-4bit",
      "label": "Qwen2.5 14.0B Instruct",
      "repo": "lmstudio-community/Qwen2.5-Coder-14B-Instruct-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-14B-Instruct-MLX-4bit",
      "family": "Qwen2.5",
      "size": "14.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen2.5-Coder-14B-Instruct-MLX-4bit. Tool-calling. Теги: mlx, safetensors, qwen2, code, codeqwen, chat.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 9400000000
    },
    {
      "id": "llama-3-2-1b-instruct-4bit",
      "label": "Llama 3 1.0B Instruct",
      "repo": "mlx-community/Llama-3.2-1B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Llama-3.2-1B-Instruct-4bit",
      "family": "Llama 3",
      "size": "1.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Llama-3.2-1B-Instruct-4bit. Tool-calling. Теги: transformers, safetensors, llama, text-generation, facebook, meta.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "compact",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 950000000
    },
    {
      "id": "llama-3-2-3b-instruct-4bit",
      "label": "Llama 3 3.0B Instruct",
      "repo": "mlx-community/Llama-3.2-3B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Llama-3.2-3B-Instruct-4bit",
      "family": "Llama 3",
      "size": "3.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Llama-3.2-3B-Instruct-4bit. Tool-calling. Теги: transformers, safetensors, llama, text-generation, facebook, meta.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "balanced",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 2250000000
    },
    {
      "id": "qwen3-4b-instruct-2507-mlx-4bit",
      "label": "Qwen3 4.0B Instruct",
      "repo": "lmstudio-community/Qwen3-4B-Instruct-2507-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-4B-Instruct-2507-MLX-4bit",
      "family": "Qwen3",
      "size": "4.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-4B-Instruct-2507-MLX-4bit. Tool-calling. Теги: transformers, safetensors, qwen3, text-generation, mlx, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "balanced",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 2900000000
    },
    {
      "id": "qwen3-next-80b-a3b-instruct-mlx-4bit",
      "label": "Qwen3 80.0B Instruct",
      "repo": "lmstudio-community/Qwen3-Next-80B-A3B-Instruct-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-Next-80B-A3B-Instruct-MLX-4bit",
      "family": "Qwen3",
      "size": "80.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-Next-80B-A3B-Instruct-MLX-4bit. Tool-calling. Теги: transformers, safetensors, qwen3_next, text-generation, mlx, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 52300000000
    },
    {
      "id": "qwen3-30b-a3b-instruct-2507-mlx-4bit",
      "label": "Qwen3 30.0B Instruct",
      "repo": "lmstudio-community/Qwen3-30B-A3B-Instruct-2507-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-30B-A3B-Instruct-2507-MLX-4bit",
      "family": "Qwen3",
      "size": "30.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-30B-A3B-Instruct-2507-MLX-4bit. Tool-calling. Теги: transformers, safetensors, qwen3_moe, text-generation, mlx, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 19800000000
    },
    {
      "id": "meta-llama-3-1-8b-instruct-4bit",
      "label": "Llama 3 8.0B Instruct",
      "repo": "mlx-community/Meta-Llama-3.1-8B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Meta-Llama-3.1-8B-Instruct-4bit",
      "family": "Llama 3",
      "size": "8.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Meta-Llama-3.1-8B-Instruct-4bit. Tool-calling. Теги: mlx, safetensors, llama, facebook, meta, pytorch.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 5500000000
    },
    {
      "id": "qwen2-5-coder-32b-instruct-mlx-4bit",
      "label": "Qwen2.5 32.0B Instruct",
      "repo": "lmstudio-community/Qwen2.5-Coder-32B-Instruct-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-32B-Instruct-MLX-4bit",
      "family": "Qwen2.5",
      "size": "32.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen2.5-Coder-32B-Instruct-MLX-4bit. Tool-calling. Теги: mlx, safetensors, qwen2, code, codeqwen, chat.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 21100000000
    },
    {
      "id": "llama-3-3-70b-instruct-4bit",
      "label": "Llama 3 70.0B Instruct",
      "repo": "mlx-community/Llama-3.3-70B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Llama-3.3-70B-Instruct-4bit",
      "family": "Llama 3",
      "size": "70.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Llama-3.3-70B-Instruct-4bit. Tool-calling. Теги: transformers, safetensors, llama, text-generation, facebook, meta.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 45800000000
    },
    {
      "id": "qwen3-next-80b-a3b-instruct-4bit",
      "label": "Qwen3 80.0B Instruct",
      "repo": "mlx-community/Qwen3-Next-80B-A3B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen3-Next-80B-A3B-Instruct-4bit",
      "family": "Qwen3",
      "size": "80.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen3-Next-80B-A3B-Instruct-4bit. Tool-calling. Теги: mlx, safetensors, qwen3_next, text-generation, conversational, base_model:Qwen/Qwen3-Next-80B-A3B-Instruct.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 52300000000
    },
    {
      "id": "qwen3-coder-480b-a35b-instruct-4bit",
      "label": "Qwen3 480.0B Instruct",
      "repo": "mlx-community/Qwen3-Coder-480B-A35B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen3-Coder-480B-A35B-Instruct-4bit",
      "family": "Qwen3",
      "size": "480.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen3-Coder-480B-A35B-Instruct-4bit. Tool-calling. Теги: mlx, safetensors, qwen3_moe, text-generation, conversational, base_model:Qwen/Qwen3-Coder-480B-A35B-Instruct.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 312300000000
    },
    {
      "id": "meta-llama-3-1-70b-instruct-4bit",
      "label": "Llama 3 70.0B Instruct",
      "repo": "mlx-community/Meta-Llama-3.1-70B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Meta-Llama-3.1-70B-Instruct-4bit",
      "family": "Llama 3",
      "size": "70.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Meta-Llama-3.1-70B-Instruct-4bit. Tool-calling. Теги: transformers, safetensors, llama, text-generation, facebook, meta.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 45800000000
    },
    {
      "id": "qwen3-235b-a22b-instruct-2507-4bit",
      "label": "Qwen3 235.0B Instruct",
      "repo": "mlx-community/Qwen3-235B-A22B-Instruct-2507-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen3-235B-A22B-Instruct-2507-4bit",
      "family": "Qwen3",
      "size": "235.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen3-235B-A22B-Instruct-2507-4bit. Tool-calling. Теги: mlx, safetensors, qwen3_moe, text-generation, conversational, base_model:Qwen/Qwen3-235B-A22B-Instruct-2507.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 153050000000
    },
    {
      "id": "mistral-small-3-2-24b-instruct-2506-mlx-4bit",
      "label": "Mistral 24.0B Instruct",
      "repo": "lmstudio-community/Mistral-Small-3.2-24B-Instruct-2506-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Mistral-Small-3.2-24B-Instruct-2506-MLX-4bit",
      "family": "Mistral",
      "size": "24.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Mistral-Small-3.2-24B-Instruct-2506-MLX-4bit. Tool-calling. Теги: mlx, safetensors, mistral3, image-text-to-text, conversational, en.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 15900000000
    },
    {
      "id": "qwen3-4b-instruct-2507-4bit",
      "label": "Qwen3 4.0B Instruct",
      "repo": "mlx-community/Qwen3-4B-Instruct-2507-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen3-4B-Instruct-2507-4bit",
      "family": "Qwen3",
      "size": "4.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen3-4B-Instruct-2507-4bit. Tool-calling. Теги: mlx, safetensors, qwen3, text-generation, conversational, base_model:Qwen/Qwen3-4B-Instruct-2507.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "balanced",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 2900000000
    },
    {
      "id": "qwen2-5-3b-instruct-4bit",
      "label": "Qwen2.5 3.0B Instruct",
      "repo": "mlx-community/Qwen2.5-3B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen2.5-3B-Instruct-4bit",
      "family": "Qwen2.5",
      "size": "3.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen2.5-3B-Instruct-4bit. Tool-calling. Теги: mlx, safetensors, qwen2, chat, text-generation, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "balanced",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 2250000000
    },
    {
      "id": "qwen2-5-7b-instruct-4bit",
      "label": "Qwen2.5 7.0B Instruct",
      "repo": "mlx-community/Qwen2.5-7B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen2.5-7B-Instruct-4bit",
      "family": "Qwen2.5",
      "size": "7.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen2.5-7B-Instruct-4bit. Tool-calling. Теги: mlx, safetensors, qwen2, chat, text-generation, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 4850000000
    },
    {
      "id": "mistral-nemo-instruct-2407-4bit",
      "label": "Mistral 4.0B Instruct",
      "repo": "mlx-community/Mistral-Nemo-Instruct-2407-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Mistral-Nemo-Instruct-2407-4bit",
      "family": "Mistral",
      "size": "4.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Mistral-Nemo-Instruct-2407-4bit. Tool-calling. Теги: mlx, safetensors, mistral, en, fr, de.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "balanced",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 2900000000
    },
    {
      "id": "qwen2-5-1-5b-instruct-4bit",
      "label": "Qwen2.5 1.5B Instruct",
      "repo": "mlx-community/Qwen2.5-1.5B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen2.5-1.5B-Instruct-4bit",
      "family": "Qwen2.5",
      "size": "1.5B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen2.5-1.5B-Instruct-4bit. Tool-calling. Теги: mlx, safetensors, qwen2, chat, text-generation, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "compact",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 1275000000
    },
    {
      "id": "qwen3-vl-4b-instruct-4bit",
      "label": "Qwen3-VL 4.0B Instruct",
      "repo": "mlx-community/Qwen3-VL-4B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen3-VL-4B-Instruct-4bit",
      "family": "Qwen3-VL",
      "size": "4.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen3-VL-4B-Instruct-4bit. Vision + Tool-calling. Теги: mlx, safetensors, qwen3_vl, image-text-to-text, conversational, license:apache-2.0.",
      "supports_tools": true,
      "supports_vision": true,
      "supports_documents": true,
      "recommended_tier": "balanced",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 2900000000
    },
    {
      "id": "qwen2-5-0-5b-instruct-4bit",
      "label": "Qwen2.5 0.5B Instruct",
      "repo": "mlx-community/Qwen2.5-0.5B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen2.5-0.5B-Instruct-4bit",
      "family": "Qwen2.5",
      "size": "0.5B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen2.5-0.5B-Instruct-4bit. Tool-calling. Теги: mlx, safetensors, qwen2, chat, text-generation, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "compact",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 625000000
    },
    {
      "id": "qwen2-5-coder-7b-instruct-mlx-4bit",
      "label": "Qwen2.5 7.0B Instruct",
      "repo": "lmstudio-community/Qwen2.5-Coder-7B-Instruct-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-7B-Instruct-MLX-4bit",
      "family": "Qwen2.5",
      "size": "7.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen2.5-Coder-7B-Instruct-MLX-4bit. Tool-calling. Теги: mlx, safetensors, qwen2, code, codeqwen, chat.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 4850000000
    },
    {
      "id": "qwen2-vl-2b-instruct-4bit",
      "label": "Qwen 2.0B Instruct",
      "repo": "mlx-community/Qwen2-VL-2B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen2-VL-2B-Instruct-4bit",
      "family": "Qwen",
      "size": "2.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen2-VL-2B-Instruct-4bit. Vision + Tool-calling. Теги: transformers, safetensors, qwen2_vl, image-text-to-text, multimodal, mlx.",
      "supports_tools": true,
      "supports_vision": true,
      "supports_documents": true,
      "recommended_tier": "compact",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 1600000000
    },
    {
      "id": "qwen3-235b-a22b-instruct-2507-mlx-4bit",
      "label": "Qwen3 235.0B Instruct",
      "repo": "lmstudio-community/Qwen3-235B-A22B-Instruct-2507-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-235B-A22B-Instruct-2507-MLX-4bit",
      "family": "Qwen3",
      "size": "235.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-235B-A22B-Instruct-2507-MLX-4bit. Tool-calling. Теги: transformers, safetensors, qwen3_moe, text-generation, mlx, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 153050000000
    },
    {
      "id": "qwen3-vl-2b-instruct-4bit",
      "label": "Qwen3-VL 2.0B Instruct",
      "repo": "mlx-community/Qwen3-VL-2B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen3-VL-2B-Instruct-4bit",
      "family": "Qwen3-VL",
      "size": "2.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen3-VL-2B-Instruct-4bit. Vision + Tool-calling. Теги: transformers, safetensors, qwen3_vl, image-text-to-text, mlx, conversational.",
      "supports_tools": true,
      "supports_vision": true,
      "supports_documents": true,
      "recommended_tier": "compact",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 1600000000
    },
    {
      "id": "mistral-7b-instruct-v0-3-4bit",
      "label": "Mistral 7.0B Instruct",
      "repo": "mlx-community/Mistral-7B-Instruct-v0.3-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Mistral-7B-Instruct-v0.3-4bit",
      "family": "Mistral",
      "size": "7.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Mistral-7B-Instruct-v0.3-4bit. Tool-calling. Теги: mlx, safetensors, mistral, license:apache-2.0, region:us.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 4850000000
    },
    {
      "id": "qwen3-coder-480b-a35b-instruct-mlx-4bit",
      "label": "Qwen3 480.0B Instruct",
      "repo": "lmstudio-community/Qwen3-Coder-480B-A35B-Instruct-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-Coder-480B-A35B-Instruct-MLX-4bit",
      "family": "Qwen3",
      "size": "480.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-Coder-480B-A35B-Instruct-MLX-4bit. Tool-calling. Теги: transformers, safetensors, qwen3_moe, text-generation, mlx, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 312300000000
    },
    {
      "id": "ministral-3-8b-instruct-2512-4bit",
      "label": "Ministral 8.0B Instruct",
      "repo": "mlx-community/Ministral-3-8B-Instruct-2512-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Ministral-3-8B-Instruct-2512-4bit",
      "family": "Ministral",
      "size": "8.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Ministral-3-8B-Instruct-2512-4bit. Tool-calling. Теги: vllm, safetensors, mistral3, mistral-common, mlx, en.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 5500000000
    },
    {
      "id": "qwen2-5-vl-3b-instruct-4bit",
      "label": "Qwen2.5 3.0B Instruct",
      "repo": "mlx-community/Qwen2.5-VL-3B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen2.5-VL-3B-Instruct-4bit",
      "family": "Qwen2.5",
      "size": "3.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen2.5-VL-3B-Instruct-4bit. Vision + Tool-calling. Теги: transformers, safetensors, qwen2_5_vl, image-text-to-text, multimodal, mlx.",
      "supports_tools": true,
      "supports_vision": true,
      "supports_documents": true,
      "recommended_tier": "balanced",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 2250000000
    },
    {
      "id": "meta-llama-3-8b-instruct-4bit",
      "label": "Llama 3 8.0B Instruct",
      "repo": "mlx-community/Meta-Llama-3-8B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Meta-Llama-3-8B-Instruct-4bit",
      "family": "Llama 3",
      "size": "8.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Meta-Llama-3-8B-Instruct-4bit. Tool-calling. Теги: mlx, safetensors, llama, facebook, meta, pytorch.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 5500000000
    },
    {
      "id": "qwen2-5-coder-7b-instruct-4bit",
      "label": "Qwen2.5 7.0B Instruct",
      "repo": "mlx-community/Qwen2.5-Coder-7B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen2.5-Coder-7B-Instruct-4bit",
      "family": "Qwen2.5",
      "size": "7.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen2.5-Coder-7B-Instruct-4bit. Tool-calling. Теги: transformers, safetensors, qwen2, text-generation, code, codeqwen.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 4850000000
    },
    {
      "id": "ministral-3-14b-instruct-2512-4bit",
      "label": "Ministral 14.0B Instruct",
      "repo": "mlx-community/Ministral-3-14B-Instruct-2512-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Ministral-3-14B-Instruct-2512-4bit",
      "family": "Ministral",
      "size": "14.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Ministral-3-14B-Instruct-2512-4bit. Tool-calling. Теги: vllm, safetensors, mistral3, mistral-common, mlx, en.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 9400000000
    },
    {
      "id": "qwen2-5-14b-instruct-4bit",
      "label": "Qwen2.5 14.0B Instruct",
      "repo": "mlx-community/Qwen2.5-14B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen2.5-14B-Instruct-4bit",
      "family": "Qwen2.5",
      "size": "14.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen2.5-14B-Instruct-4bit. Tool-calling. Теги: mlx, safetensors, qwen2, chat, text-generation, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 9400000000
    },
    {
      "id": "qwen2-5-coder-1-5b-instruct-4bit",
      "label": "Qwen2.5 1.5B Instruct",
      "repo": "mlx-community/Qwen2.5-Coder-1.5B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen2.5-Coder-1.5B-Instruct-4bit",
      "family": "Qwen2.5",
      "size": "1.5B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen2.5-Coder-1.5B-Instruct-4bit. Tool-calling. Теги: transformers, safetensors, qwen2, text-generation, code, codeqwen.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "compact",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 1275000000
    },
    {
      "id": "qwen3-coder-30b-a3b-instruct-4bit",
      "label": "Qwen3 30.0B Instruct",
      "repo": "mlx-community/Qwen3-Coder-30B-A3B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen3-Coder-30B-A3B-Instruct-4bit",
      "family": "Qwen3",
      "size": "30.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen3-Coder-30B-A3B-Instruct-4bit. Tool-calling. Теги: mlx, safetensors, qwen3_moe, text-generation, conversational, base_model:Qwen/Qwen3-Coder-30B-A3B-Instruct.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 19800000000
    },
    {
      "id": "qwen2-5-14b-instruct-mlx-4bit",
      "label": "Qwen2.5 14.0B Instruct",
      "repo": "lmstudio-community/Qwen2.5-14B-Instruct-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen2.5-14B-Instruct-MLX-4bit",
      "family": "Qwen2.5",
      "size": "14.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen2.5-14B-Instruct-MLX-4bit. Tool-calling. Теги: mlx, safetensors, qwen2, chat, text-generation, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 9400000000
    },
    {
      "id": "qwen2-5-coder-14b-instruct-4bit",
      "label": "Qwen2.5 14.0B Instruct",
      "repo": "mlx-community/Qwen2.5-Coder-14B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen2.5-Coder-14B-Instruct-4bit",
      "family": "Qwen2.5",
      "size": "14.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen2.5-Coder-14B-Instruct-4bit. Tool-calling. Теги: transformers, safetensors, qwen2, text-generation, code, codeqwen.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 9400000000
    },
    {
      "id": "qwen2-5-coder-3b-instruct-4bit",
      "label": "Qwen2.5 3.0B Instruct",
      "repo": "mlx-community/Qwen2.5-Coder-3B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen2.5-Coder-3B-Instruct-4bit",
      "family": "Qwen2.5",
      "size": "3.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen2.5-Coder-3B-Instruct-4bit. Tool-calling. Теги: transformers, safetensors, qwen2, text-generation, code, codeqwen.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "balanced",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 2250000000
    },
    {
      "id": "ministral-8b-instruct-2410-4bit",
      "label": "Ministral 8.0B Instruct",
      "repo": "mlx-community/Ministral-8B-Instruct-2410-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Ministral-8B-Instruct-2410-4bit",
      "family": "Ministral",
      "size": "8.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Ministral-8B-Instruct-2410-4bit. Tool-calling. Теги: vllm, safetensors, mistral, mlx, en, fr.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 5500000000
    },
    {
      "id": "qwen2-5-vl-7b-instruct-4bit",
      "label": "Qwen2.5 7.0B Instruct",
      "repo": "mlx-community/Qwen2.5-VL-7B-Instruct-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen2.5-VL-7B-Instruct-4bit",
      "family": "Qwen2.5",
      "size": "7.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen2.5-VL-7B-Instruct-4bit. Vision + Tool-calling. Теги: transformers, safetensors, qwen2_5_vl, image-text-to-text, multimodal, mlx.",
      "supports_tools": true,
      "supports_vision": true,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 4850000000
    },
    {
      "id": "qwen3-vl-4b-instruct-mlx-8bit",
      "label": "Qwen3-VL 4.0B Instruct",
      "repo": "lmstudio-community/Qwen3-VL-4B-Instruct-MLX-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-VL-4B-Instruct-MLX-8bit",
      "family": "Qwen3-VL",
      "size": "4.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-VL-4B-Instruct-MLX-8bit. Vision + Tool-calling. Теги: mlx, safetensors, qwen3_vl, image-text-to-text, conversational, base_model:Qwen/Qwen3-VL-4B-Instruct.",
      "supports_tools": true,
      "supports_vision": true,
      "supports_documents": true,
      "recommended_tier": "balanced",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 2900000000
    },
    {
      "id": "qwen3-vl-8b-instruct-mlx-8bit",
      "label": "Qwen3-VL 8.0B Instruct",
      "repo": "lmstudio-community/Qwen3-VL-8B-Instruct-MLX-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-VL-8B-Instruct-MLX-8bit",
      "family": "Qwen3-VL",
      "size": "8.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-VL-8B-Instruct-MLX-8bit. Vision + Tool-calling. Теги: mlx, safetensors, qwen3_vl, image-text-to-text, conversational, base_model:Qwen/Qwen3-VL-8B-Instruct.",
      "supports_tools": true,
      "supports_vision": true,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 5500000000
    },
    {
      "id": "qwen3-coder-30b-a3b-instruct-mlx-8bit",
      "label": "Qwen3 30.0B Instruct",
      "repo": "lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-8bit",
      "family": "Qwen3",
      "size": "30.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-Coder-30B-A3B-Instruct-MLX-8bit. Tool-calling. Теги: transformers, safetensors, qwen3_moe, text-generation, mlx, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 19800000000
    },
    {
      "id": "qwen3-vl-30b-a3b-instruct-mlx-8bit",
      "label": "Qwen3-VL 30.0B Instruct",
      "repo": "lmstudio-community/Qwen3-VL-30B-A3B-Instruct-MLX-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-VL-30B-A3B-Instruct-MLX-8bit",
      "family": "Qwen3-VL",
      "size": "30.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-VL-30B-A3B-Instruct-MLX-8bit. Vision + Tool-calling. Теги: mlx, safetensors, qwen3_vl_moe, image-text-to-text, conversational, base_model:Qwen/Qwen3-VL-30B-A3B-Instruct.",
      "supports_tools": true,
      "supports_vision": true,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 19800000000
    },
    {
      "id": "qwen2-5-coder-14b-instruct-mlx-8bit",
      "label": "Qwen2.5 14.0B Instruct",
      "repo": "lmstudio-community/Qwen2.5-Coder-14B-Instruct-MLX-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-14B-Instruct-MLX-8bit",
      "family": "Qwen2.5",
      "size": "14.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen2.5-Coder-14B-Instruct-MLX-8bit. Tool-calling. Теги: mlx, safetensors, qwen2, code, codeqwen, chat.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 9400000000
    },
    {
      "id": "qwen3-4b-instruct-2507-mlx-8bit",
      "label": "Qwen3 4.0B Instruct",
      "repo": "lmstudio-community/Qwen3-4B-Instruct-2507-MLX-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-4B-Instruct-2507-MLX-8bit",
      "family": "Qwen3",
      "size": "4.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-4B-Instruct-2507-MLX-8bit. Tool-calling. Теги: transformers, safetensors, qwen3, text-generation, mlx, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "balanced",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 2900000000
    },
    {
      "id": "qwen3-next-80b-a3b-instruct-mlx-8bit",
      "label": "Qwen3 80.0B Instruct",
      "repo": "lmstudio-community/Qwen3-Next-80B-A3B-Instruct-MLX-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-Next-80B-A3B-Instruct-MLX-8bit",
      "family": "Qwen3",
      "size": "80.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-Next-80B-A3B-Instruct-MLX-8bit. Tool-calling. Теги: transformers, safetensors, qwen3_next, text-generation, mlx, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 52300000000
    },
    {
      "id": "qwen3-30b-a3b-instruct-2507-mlx-8bit",
      "label": "Qwen3 30.0B Instruct",
      "repo": "lmstudio-community/Qwen3-30B-A3B-Instruct-2507-MLX-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-30B-A3B-Instruct-2507-MLX-8bit",
      "family": "Qwen3",
      "size": "30.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-30B-A3B-Instruct-2507-MLX-8bit. Tool-calling. Теги: transformers, safetensors, qwen3_moe, text-generation, mlx, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 19800000000
    },
    {
      "id": "meta-llama-3-1-8b-instruct-8bit",
      "label": "Llama 3 8.0B Instruct",
      "repo": "mlx-community/Meta-Llama-3.1-8B-Instruct-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Meta-Llama-3.1-8B-Instruct-8bit",
      "family": "Llama 3",
      "size": "8.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Meta-Llama-3.1-8B-Instruct-8bit. Tool-calling. Теги: mlx, safetensors, llama, facebook, meta, pytorch.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 5500000000
    },
    {
      "id": "llama-3-3-70b-instruct-8bit",
      "label": "Llama 3 70.0B Instruct",
      "repo": "mlx-community/Llama-3.3-70B-Instruct-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Llama-3.3-70B-Instruct-8bit",
      "family": "Llama 3",
      "size": "70.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Llama-3.3-70B-Instruct-8bit. Tool-calling. Теги: transformers, safetensors, llama, text-generation, facebook, meta.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 45800000000
    },
    {
      "id": "qwen2-5-coder-32b-instruct-mlx-8bit",
      "label": "Qwen2.5 32.0B Instruct",
      "repo": "lmstudio-community/Qwen2.5-Coder-32B-Instruct-MLX-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen2.5-Coder-32B-Instruct-MLX-8bit",
      "family": "Qwen2.5",
      "size": "32.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen2.5-Coder-32B-Instruct-MLX-8bit. Tool-calling. Теги: mlx, safetensors, qwen2, code, codeqwen, chat.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 21100000000
    },
    {
      "id": "llama-3-2-3b-instruct-8bit",
      "label": "Llama 3 3.0B Instruct",
      "repo": "mlx-community/Llama-3.2-3B-Instruct-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Llama-3.2-3B-Instruct-8bit",
      "family": "Llama 3",
      "size": "3.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Llama-3.2-3B-Instruct-8bit. Tool-calling. Теги: transformers, safetensors, llama, text-generation, facebook, meta.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "balanced",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 2250000000
    },
    {
      "id": "qwen3-next-80b-a3b-instruct-8bit",
      "label": "Qwen3 80.0B Instruct",
      "repo": "mlx-community/Qwen3-Next-80B-A3B-Instruct-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen3-Next-80B-A3B-Instruct-8bit",
      "family": "Qwen3",
      "size": "80.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen3-Next-80B-A3B-Instruct-8bit. Tool-calling. Теги: mlx, safetensors, qwen3_next, text-generation, conversational, base_model:Qwen/Qwen3-Next-80B-A3B-Instruct.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 52300000000
    },
    {
      "id": "qwen3-235b-a22b-instruct-2507-8bit",
      "label": "Qwen3 235.0B Instruct",
      "repo": "mlx-community/Qwen3-235B-A22B-Instruct-2507-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen3-235B-A22B-Instruct-2507-8bit",
      "family": "Qwen3",
      "size": "235.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen3-235B-A22B-Instruct-2507-8bit. Tool-calling. Теги: mlx, safetensors, qwen3_moe, text-generation, conversational, base_model:Qwen/Qwen3-235B-A22B-Instruct-2507.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 153050000000
    },
    {
      "id": "qwen3-coder-480b-a35b-instruct-8bit",
      "label": "Qwen3 480.0B Instruct",
      "repo": "mlx-community/Qwen3-Coder-480B-A35B-Instruct-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/mlx-community/Qwen3-Coder-480B-A35B-Instruct-8bit",
      "family": "Qwen3",
      "size": "480.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: mlx-community/Qwen3-Coder-480B-A35B-Instruct-8bit. Tool-calling. Теги: mlx, safetensors, qwen3_moe, text-generation, conversational, base_model:Qwen/Qwen3-Coder-480B-A35B-Instruct.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 312300000000
    },
    {
      "id": "mistral-small-3-2-24b-instruct-2506-mlx-8bit",
      "label": "Mistral 24.0B Instruct",
      "repo": "lmstudio-community/Mistral-Small-3.2-24B-Instruct-2506-MLX-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Mistral-Small-3.2-24B-Instruct-2506-MLX-8bit",
      "family": "Mistral",
      "size": "24.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Mistral-Small-3.2-24B-Instruct-2506-MLX-8bit. Tool-calling. Теги: vllm, safetensors, mistral3, mlx, image-text-to-text, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 15900000000
    },
    {
      "id": "qwen3-coder-next-mlx-8bit",
      "label": "Qwen3 8.0B Instruct",
      "repo": "lmstudio-community/Qwen3-Coder-Next-MLX-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-Coder-Next-MLX-8bit",
      "family": "Qwen3",
      "size": "8.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-Coder-Next-MLX-8bit. Tool-calling. Теги: mlx, safetensors, qwen3_next, base_model:Qwen/Qwen3-Coder-Next, base_model:quantized:Qwen/Qwen3-Coder-Next, license:apache-2.0.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 5500000000
    },
    {
      "id": "qwen3-coder-next-mlx-4bit",
      "label": "Qwen3 4.0B Instruct",
      "repo": "lmstudio-community/Qwen3-Coder-Next-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-Coder-Next-MLX-4bit",
      "family": "Qwen3",
      "size": "4.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-Coder-Next-MLX-4bit. Tool-calling. Теги: mlx, safetensors, qwen3_next, base_model:Qwen/Qwen3-Coder-Next, base_model:quantized:Qwen/Qwen3-Coder-Next, license:apache-2.0.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "balanced",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 2900000000
    },
    {
      "id": "deepseek-r1-0528-qwen3-8b-mlx-4bit",
      "label": "Qwen3 8.0B Instruct",
      "repo": "lmstudio-community/DeepSeek-R1-0528-Qwen3-8B-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/DeepSeek-R1-0528-Qwen3-8B-MLX-4bit",
      "family": "Qwen3",
      "size": "8.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/DeepSeek-R1-0528-Qwen3-8B-MLX-4bit. Tool-calling. Теги: mlx, safetensors, qwen3, text-generation, conversational, base_model:deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 5500000000
    },
    {
      "id": "deepseek-r1-0528-qwen3-8b-mlx-8bit",
      "label": "Qwen3 8.0B Instruct",
      "repo": "lmstudio-community/DeepSeek-R1-0528-Qwen3-8B-MLX-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/DeepSeek-R1-0528-Qwen3-8B-MLX-8bit",
      "family": "Qwen3",
      "size": "8.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/DeepSeek-R1-0528-Qwen3-8B-MLX-8bit. Tool-calling. Теги: mlx, safetensors, qwen3, text-generation, conversational, base_model:deepseek-ai/DeepSeek-R1-0528-Qwen3-8B.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "performance",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 5500000000
    },
    {
      "id": "qwen3-4b-thinking-2507-mlx-4bit",
      "label": "Qwen3 4.0B Instruct",
      "repo": "lmstudio-community/Qwen3-4B-Thinking-2507-MLX-4bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-4B-Thinking-2507-MLX-4bit",
      "family": "Qwen3",
      "size": "4.0B",
      "quantization": "MLX 4bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-4B-Thinking-2507-MLX-4bit. Tool-calling. Теги: transformers, safetensors, qwen3, text-generation, mlx, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "balanced",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 2900000000
    },
    {
      "id": "qwen3-4b-thinking-2507-mlx-8bit",
      "label": "Qwen3 4.0B Instruct",
      "repo": "lmstudio-community/Qwen3-4B-Thinking-2507-MLX-8bit",
      "source": "huggingface",
      "homepage": "https://huggingface.co/lmstudio-community/Qwen3-4B-Thinking-2507-MLX-8bit",
      "family": "Qwen3",
      "size": "4.0B",
      "quantization": "MLX 8bit",
      "description": "Обнаружена на HuggingFace: lmstudio-community/Qwen3-4B-Thinking-2507-MLX-8bit. Tool-calling. Теги: transformers, safetensors, qwen3, text-generation, mlx, conversational.",
      "supports_tools": true,
      "supports_vision": false,
      "supports_documents": true,
      "recommended_tier": "balanced",
      "max_context": 8192,
      "estimated_unified_memory_bytes": 2900000000
    }
  ]
}